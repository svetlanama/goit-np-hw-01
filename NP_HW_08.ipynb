{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-colab"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/svetlanama/goit-np-hw-01/blob/main/NP_HW_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Домашнє завдання 8: Квадратичний дискримінантний аналіз (QDA)\n",
    "\n",
    "## Мета роботи\n",
    "\n",
    "У цій роботі ми реалізуємо квадратичний дискримінантний аналіз (Quadratic Discriminant Analysis, QDA) з нуля та порівняємо результати з реалізацією sklearn.\n",
    "\n",
    "**Набір даних**: Iris Dataset (sklearn)\n",
    "\n",
    "## Теоретичні основи QDA\n",
    "\n",
    "Квадратичний дискримінантний аналіз - це метод класифікації, який моделює розподіл ознак кожного класу як багатовимірний нормальний (гаусівський) розподіл з власною матрицею коваріації для кожного класу.\n",
    "\n",
    "### Дискримінантна функція:\n",
    "\n",
    "$$\\delta_k(x) = -\\frac{1}{2}\\log|\\Sigma_k| - \\frac{1}{2}(x - \\mu_k)^T \\Sigma_k^{-1} (x - \\mu_k) + \\log(\\pi_k)$$\n",
    "\n",
    "де:\n",
    "- $\\mu_k$ - вектор середніх класу k\n",
    "- $\\Sigma_k$ - матриця коваріації класу k\n",
    "- $\\pi_k$ - апріорна ймовірність класу k\n",
    "- $|\\Sigma_k|$ - визначник матриці коваріації\n",
    "\n",
    "Клас передбачається як: $\\hat{y} = \\arg\\max_k \\delta_k(x)$\n",
    "\n",
    "## Завдання\n",
    "\n",
    "1. Завантажити набір даних Iris\n",
    "2. Розділити на train/test\n",
    "3. Відібрати ознаки для кожного класу\n",
    "4. Обчислити матриці коваріації\n",
    "5. Обчислити обернені матриці коваріації\n",
    "6. Обчислити апріорні ймовірності\n",
    "7. Реалізувати дискримінантну функцію для одного зразка\n",
    "8. Реалізувати для всієї матриці тестових даних\n",
    "9. Порівняти з sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis\n",
    "10. Проаналізувати результати"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## Крок 1: Завантаження набору даних Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Імпорт необхідних бібліотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Налаштування відображення\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"✓ Бібліотеки завантажено\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-iris"
   },
   "outputs": [],
   "source": [
    "# Завантажуємо набір даних Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Створюємо DataFrame для зручності\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['target'] = y\n",
    "df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "print(f\"Розмір датасету: {X.shape}\")\n",
    "print(f\"Кількість класів: {len(np.unique(y))}\")\n",
    "print(f\"Назви класів: {iris.target_names}\")\n",
    "print(f\"\\nНазви ознак:\")\n",
    "for i, name in enumerate(iris.feature_names):\n",
    "    print(f\"  {i}: {name}\")\n",
    "\n",
    "print(f\"\\nПерші 5 рядків:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-info"
   },
   "outputs": [],
   "source": [
    "# Розподіл класів\n",
    "print(\"Розподіл класів:\")\n",
    "print(df['species'].value_counts())\n",
    "\n",
    "# Візуалізація\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Гістограма\n",
    "df['species'].value_counts().plot(kind='bar', ax=axes[0], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0].set_title('Розподіл класів (Гістограма)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Клас', fontsize=12)\n",
    "axes[0].set_ylabel('Кількість зразків', fontsize=12)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "\n",
    "# Кругова діаграма\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "df['species'].value_counts().plot(kind='pie', ax=axes[1], colors=colors, autopct='%1.1f%%',\n",
    "                                   startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Розподіл класів (Pie Chart)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## Крок 2: Розділення на train/test вибірки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-test-split"
   },
   "outputs": [],
   "source": [
    "# Розділяємо дані на тренувальні та тестові (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Розмір тренувальної вибірки: {X_train.shape}\")\n",
    "print(f\"Розмір тестової вибірки: {X_test.shape}\")\n",
    "\n",
    "print(f\"\\nРозподіл класів у тренувальній вибірці:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for class_idx, count in zip(unique, counts):\n",
    "    print(f\"  {iris.target_names[class_idx]}: {count}\")\n",
    "\n",
    "print(f\"\\nРозподіл класів у тестовій вибірці:\")\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "for class_idx, count in zip(unique, counts):\n",
    "    print(f\"  {iris.target_names[class_idx]}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## Крок 3: Вибірка ознак для кожного класу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "select-by-class"
   },
   "outputs": [],
   "source": [
    "# Розділяємо тренувальні дані за класами\n",
    "classes = np.unique(y_train)\n",
    "n_classes = len(classes)\n",
    "\n",
    "X_by_class = {}\n",
    "for class_idx in classes:\n",
    "    X_by_class[class_idx] = X_train[y_train == class_idx]\n",
    "    print(f\"Клас {iris.target_names[class_idx]} (клас {class_idx}): {X_by_class[class_idx].shape[0]} зразків\")\n",
    "\n",
    "# Статистика для кожного класу\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"СТАТИСТИКА ОЗНАК ДЛЯ КОЖНОГО КЛАСУ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for class_idx in classes:\n",
    "    print(f\"\\nКлас {iris.target_names[class_idx]} (клас {class_idx}):\")\n",
    "    print(f\"Середні значення ознак:\")\n",
    "    means = np.mean(X_by_class[class_idx], axis=0)\n",
    "    for i, (name, mean) in enumerate(zip(iris.feature_names, means)):\n",
    "        print(f\"  {name}: {mean:.4f}\")\n",
    "    \n",
    "    print(f\"\\nСтандартні відхилення:\")\n",
    "    stds = np.std(X_by_class[class_idx], axis=0)\n",
    "    for i, (name, std) in enumerate(zip(iris.feature_names, stds)):\n",
    "        print(f\"  {name}: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4"
   },
   "source": [
    "## Крок 4: Розрахунок матриць коваріації для кожного класу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "covariance-matrices"
   },
   "outputs": [],
   "source": [
    "def calculate_covariance_matrix(X):\n",
    "    \"\"\"\n",
    "    Обчислює матрицю коваріації для матриці ознак X.\n",
    "    \n",
    "    Формула: Cov(X) = (1/(n-1)) * (X - mean)^T * (X - mean)\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    cov_matrix = (X_centered.T @ X_centered) / (n_samples - 1)\n",
    "    return cov_matrix\n",
    "\n",
    "# Обчислюємо матриці коваріації для кожного класу\n",
    "covariance_matrices = {}\n",
    "\n",
    "for class_idx in classes:\n",
    "    cov_matrix = calculate_covariance_matrix(X_by_class[class_idx])\n",
    "    covariance_matrices[class_idx] = cov_matrix\n",
    "    \n",
    "    print(f\"Матриця коваріації для класу {iris.target_names[class_idx]}:\")\n",
    "    print(cov_matrix)\n",
    "    print(f\"Визначник: {np.linalg.det(cov_matrix):.6f}\")\n",
    "    print()\n",
    "\n",
    "# Візуалізація матриць коваріації\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "colors_map = ['Blues', 'Reds', 'Greens']\n",
    "\n",
    "for idx, class_idx in enumerate(classes):\n",
    "    sns.heatmap(covariance_matrices[class_idx], \n",
    "                annot=True, \n",
    "                fmt='.3f', \n",
    "                cmap=colors_map[idx],\n",
    "                xticklabels=[f'F{i+1}' for i in range(4)],\n",
    "                yticklabels=[f'F{i+1}' for i in range(4)],\n",
    "                ax=axes[idx],\n",
    "                cbar_kws={'label': 'Коваріація'})\n",
    "    axes[idx].set_title(f'Матриця коваріації: {iris.target_names[class_idx]}', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Матриці коваріації обчислено\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5"
   },
   "source": [
    "## Крок 5: Обчислення обернених матриць коваріації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inverse-covariance"
   },
   "outputs": [],
   "source": [
    "# Обчислюємо обернені матриці коваріації\n",
    "inverse_covariance_matrices = {}\n",
    "\n",
    "for class_idx in classes:\n",
    "    try:\n",
    "        inv_cov_matrix = np.linalg.inv(covariance_matrices[class_idx])\n",
    "        inverse_covariance_matrices[class_idx] = inv_cov_matrix\n",
    "        \n",
    "        print(f\"Обернена матриця коваріації для класу {iris.target_names[class_idx]}:\")\n",
    "        print(inv_cov_matrix)\n",
    "        \n",
    "        # Перевірка: A * A^-1 = I\n",
    "        identity_check = covariance_matrices[class_idx] @ inv_cov_matrix\n",
    "        is_identity = np.allclose(identity_check, np.eye(4))\n",
    "        print(f\"Перевірка (A * A^-1 = I): {is_identity}\")\n",
    "        print()\n",
    "        \n",
    "    except np.linalg.LinAlgError:\n",
    "        print(f\"⚠ Неможливо обчислити обернену матрицю для класу {iris.target_names[class_idx]}\")\n",
    "        print(f\"Матриця вироджена (сингулярна)\")\n",
    "        print()\n",
    "\n",
    "print(\"✓ Обернені матриці коваріації обчислено\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6"
   },
   "source": [
    "## Крок 6: Обчислення апріорних ймовірностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prior-probabilities"
   },
   "outputs": [],
   "source": [
    "# Обчислюємо апріорні ймовірності P(class) для кожного класу\n",
    "n_train_samples = len(y_train)\n",
    "prior_probabilities = {}\n",
    "\n",
    "print(\"Апріорні ймовірності класів P(class):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for class_idx in classes:\n",
    "    n_class_samples = len(X_by_class[class_idx])\n",
    "    prior_prob = n_class_samples / n_train_samples\n",
    "    prior_probabilities[class_idx] = prior_prob\n",
    "    \n",
    "    print(f\"{iris.target_names[class_idx]:15s}: {prior_prob:.4f} ({n_class_samples}/{n_train_samples})\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Сума ймовірностей: {sum(prior_probabilities.values()):.4f}\")\n",
    "\n",
    "# Візуалізація\n",
    "plt.figure(figsize=(10, 6))\n",
    "classes_names = [iris.target_names[i] for i in classes]\n",
    "probs = [prior_probabilities[i] for i in classes]\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "bars = plt.bar(classes_names, probs, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "plt.title('Апріорні ймовірності класів', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Клас', fontsize=12)\n",
    "plt.ylabel('Ймовірність P(class)', fontsize=12)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Додаємо значення на стовпчики\n",
    "for bar, prob in zip(bars, probs):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{prob:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Апріорні ймовірності обчислено\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7"
   },
   "source": [
    "## Крок 7: Дискримінантна функція для одного зразка\n",
    "\n",
    "### Формула дискримінантної функції:\n",
    "\n",
    "$$\\delta_k(x) = -\\frac{1}{2}\\log|\\Sigma_k| - \\frac{1}{2}(x - \\mu_k)^T \\Sigma_k^{-1} (x - \\mu_k) + \\log(\\pi_k)$$\n",
    "\n",
    "де:\n",
    "- $x$ - вектор ознак тестового зразка\n",
    "- $\\mu_k$ - вектор середніх значень класу k\n",
    "- $\\Sigma_k$ - матриця коваріації класу k\n",
    "- $\\Sigma_k^{-1}$ - обернена матриця коваріації класу k\n",
    "- $|\\Sigma_k|$ - визначник матриці коваріації\n",
    "- $\\pi_k$ - апріорна ймовірність класу k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "discriminant-single"
   },
   "outputs": [],
   "source": [
    "def discriminant_function_single(x, class_means, cov_matrix, inv_cov_matrix, prior_prob):\n",
    "    \"\"\"\n",
    "    Обчислює значення дискримінантної функції для одного зразка x.\n",
    "    \n",
    "    Параметри:\n",
    "    - x: вектор ознак (1D array)\n",
    "    - class_means: вектор середніх класу\n",
    "    - cov_matrix: матриця коваріації класу\n",
    "    - inv_cov_matrix: обернена матриця коваріації\n",
    "    - prior_prob: апріорна ймовірність класу\n",
    "    \n",
    "    Повертає:\n",
    "    - delta: значення дискримінантної функції\n",
    "    \"\"\"\n",
    "    # Обчислюємо компоненти формули\n",
    "    \n",
    "    # 1. Логарифм визначника матриці коваріації\n",
    "    log_det = np.log(np.linalg.det(cov_matrix))\n",
    "    \n",
    "    # 2. Різниця між x та середнім класу\n",
    "    x_centered = x - class_means\n",
    "    \n",
    "    # 3. Квадратична форма (x - μ)^T * Σ^-1 * (x - μ)\n",
    "    quadratic_form = x_centered.T @ inv_cov_matrix @ x_centered\n",
    "    \n",
    "    # 4. Логарифм апріорної ймовірності\n",
    "    log_prior = np.log(prior_prob)\n",
    "    \n",
    "    # Обчислюємо дискримінантну функцію\n",
    "    delta = -0.5 * log_det - 0.5 * quadratic_form + log_prior\n",
    "    \n",
    "    return delta\n",
    "\n",
    "# Тестуємо на першому тестовому зразку\n",
    "test_sample = X_test[0]\n",
    "true_class = y_test[0]\n",
    "\n",
    "print(\"Тестування дискримінантної функції на першому зразку:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Тестовий зразок: {test_sample}\")\n",
    "print(f\"Справжній клас: {iris.target_names[true_class]}\\n\")\n",
    "\n",
    "# Обчислюємо середні для кожного класу\n",
    "class_means = {}\n",
    "for class_idx in classes:\n",
    "    class_means[class_idx] = np.mean(X_by_class[class_idx], axis=0)\n",
    "\n",
    "# Обчислюємо дискримінантну функцію для кожного класу\n",
    "discriminant_scores = {}\n",
    "for class_idx in classes:\n",
    "    delta = discriminant_function_single(\n",
    "        test_sample,\n",
    "        class_means[class_idx],\n",
    "        covariance_matrices[class_idx],\n",
    "        inverse_covariance_matrices[class_idx],\n",
    "        prior_probabilities[class_idx]\n",
    "    )\n",
    "    discriminant_scores[class_idx] = delta\n",
    "    print(f\"δ_{class_idx}(x) [{iris.target_names[class_idx]:10s}] = {delta:.6f}\")\n",
    "\n",
    "# Визначаємо передбачений клас\n",
    "predicted_class = max(discriminant_scores, key=discriminant_scores.get)\n",
    "print(\"=\"*80)\n",
    "print(f\"Передбачений клас: {iris.target_names[predicted_class]} (клас {predicted_class})\")\n",
    "print(f\"Правильна відповідь: {iris.target_names[true_class]} (клас {true_class})\")\n",
    "print(f\"Передбачення {'✓ ПРАВИЛЬНЕ' if predicted_class == true_class else '✗ НЕПРАВИЛЬНЕ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## Крок 8: Дискримінантна функція для всієї матриці тестових даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "discriminant-full"
   },
   "outputs": [],
   "source": [
    "def qda_predict(X_test, class_means, cov_matrices, inv_cov_matrices, prior_probs, classes):\n",
    "    \"\"\"\n",
    "    Виконує класифікацію за допомогою QDA для всієї матриці тестових даних.\n",
    "    \n",
    "    Параметри:\n",
    "    - X_test: матриця тестових даних (n_samples x n_features)\n",
    "    - class_means: словник векторів середніх для кожного класу\n",
    "    - cov_matrices: словник матриць коваріації\n",
    "    - inv_cov_matrices: словник обернених матриць коваріації\n",
    "    - prior_probs: словник апріорних ймовірностей\n",
    "    - classes: масив номерів класів\n",
    "    \n",
    "    Повертає:\n",
    "    - predictions: масив передбачених класів\n",
    "    - probabilities: матриця ймовірностей (n_samples x n_classes)\n",
    "    - discriminant_values: матриця значень дискримінантних функцій\n",
    "    \"\"\"\n",
    "    n_samples = X_test.shape[0]\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    # Матриця для зберігання значень дискримінантних функцій\n",
    "    discriminant_values = np.zeros((n_samples, n_classes))\n",
    "    \n",
    "    # Обчислюємо дискримінантні функції для кожного зразка та кожного класу\n",
    "    for i, x in enumerate(X_test):\n",
    "        for j, class_idx in enumerate(classes):\n",
    "            delta = discriminant_function_single(\n",
    "                x,\n",
    "                class_means[class_idx],\n",
    "                cov_matrices[class_idx],\n",
    "                inv_cov_matrices[class_idx],\n",
    "                prior_probs[class_idx]\n",
    "            )\n",
    "            discriminant_values[i, j] = delta\n",
    "    \n",
    "    # Передбачаємо класи (argmax по стовпцям)\n",
    "    predictions = classes[np.argmax(discriminant_values, axis=1)]\n",
    "    \n",
    "    # Перетворюємо дискримінантні значення у ймовірності через softmax\n",
    "    probabilities = softmax(discriminant_values, axis=1)\n",
    "    \n",
    "    return predictions, probabilities, discriminant_values\n",
    "\n",
    "# Виконуємо передбачення на тестових даних\n",
    "y_pred_custom, probabilities_custom, discriminant_vals = qda_predict(\n",
    "    X_test,\n",
    "    class_means,\n",
    "    covariance_matrices,\n",
    "    inverse_covariance_matrices,\n",
    "    prior_probabilities,\n",
    "    classes\n",
    ")\n",
    "\n",
    "print(\"Результати класифікації власною реалізацією QDA:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Кількість тестових зразків: {len(y_test)}\")\n",
    "print(f\"\\nПеревірка перших 10 передбачень:\")\n",
    "print(f\"{'Справжній клас':<20} {'Передбачений клас':<20} {'Результат':<10}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for i in range(min(10, len(y_test))):\n",
    "    true_name = iris.target_names[y_test[i]]\n",
    "    pred_name = iris.target_names[y_pred_custom[i]]\n",
    "    correct = \"✓\" if y_test[i] == y_pred_custom[i] else \"✗\"\n",
    "    print(f\"{true_name:<20} {pred_name:<20} {correct:<10}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Точність (Accuracy): {accuracy_score(y_test, y_pred_custom):.4f} ({accuracy_score(y_test, y_pred_custom)*100:.2f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom-probabilities"
   },
   "outputs": [],
   "source": [
    "# Подивимось на ймовірності для перших 5 зразків\n",
    "print(\"Ймовірності приналежності до класів (перші 5 зразків):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(min(5, len(y_test))):\n",
    "    print(f\"\\nЗразок {i+1} (справжній клас: {iris.target_names[y_test[i]]}):\")\n",
    "    for j, class_idx in enumerate(classes):\n",
    "        prob = probabilities_custom[i, j]\n",
    "        print(f\"  P({iris.target_names[class_idx]:10s}) = {prob:.6f} ({prob*100:.2f}%)\")\n",
    "    print(f\"  Передбачений клас: {iris.target_names[y_pred_custom[i]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step9"
   },
   "source": [
    "## Крок 9: Порівняння з sklearn.QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sklearn-qda"
   },
   "outputs": [],
   "source": [
    "# Використовуємо QDA з sklearn\n",
    "qda_sklearn = QuadraticDiscriminantAnalysis()\n",
    "qda_sklearn.fit(X_train, y_train)\n",
    "y_pred_sklearn = qda_sklearn.predict(X_test)\n",
    "probabilities_sklearn = qda_sklearn.predict_proba(X_test)\n",
    "\n",
    "print(\"Результати класифікації sklearn.QuadraticDiscriminantAnalysis:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Точність (Accuracy): {accuracy_score(y_test, y_pred_sklearn):.4f} ({accuracy_score(y_test, y_pred_sklearn)*100:.2f}%)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Порівняння передбачень\n",
    "print(f\"\\nПорівняння передбачень (перші 10 зразків):\")\n",
    "print(f\"{'Справжній':<12} {'Власна QDA':<12} {'sklearn QDA':<12} {'Збіг':<10}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for i in range(min(10, len(y_test))):\n",
    "    true_name = iris.target_names[y_test[i]][:10]\n",
    "    custom_name = iris.target_names[y_pred_custom[i]][:10]\n",
    "    sklearn_name = iris.target_names[y_pred_sklearn[i]][:10]\n",
    "    match = \"✓\" if y_pred_custom[i] == y_pred_sklearn[i] else \"✗\"\n",
    "    print(f\"{true_name:<12} {custom_name:<12} {sklearn_name:<12} {match:<10}\")\n",
    "\n",
    "# Порівняння ймовірностей\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"Порівняння ймовірностей (перший зразок):\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Клас':<15} {'Власна QDA':<20} {'sklearn QDA':<20} {'Різниця':<15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for j, class_idx in enumerate(classes):\n",
    "    prob_custom = probabilities_custom[0, j]\n",
    "    prob_sklearn = probabilities_sklearn[0, j]\n",
    "    diff = abs(prob_custom - prob_sklearn)\n",
    "    print(f\"{iris.target_names[class_idx]:<15} {prob_custom:<20.10f} {prob_sklearn:<20.10f} {diff:<15.10f}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step10"
   },
   "source": [
    "## Крок 10: Детальний аналіз та порівняння результатів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison-metrics"
   },
   "outputs": [],
   "source": [
    "# Порівняння метрик\n",
    "print(\"ПОРІВНЯННЯ МЕТРИК ЯКОСТІ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
    "\n",
    "print(f\"{'Метрика':<30} {'Власна реалізація':<25} {'sklearn QDA':<25}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Accuracy':<30} {accuracy_custom:<25.4f} {accuracy_sklearn:<25.4f}\")\n",
    "print(f\"{'Accuracy (%)':<30} {accuracy_custom*100:<25.2f} {accuracy_sklearn*100:<25.2f}\")\n",
    "\n",
    "# Кількість збігів передбачень\n",
    "matching_predictions = np.sum(y_pred_custom == y_pred_sklearn)\n",
    "total_predictions = len(y_test)\n",
    "match_percentage = (matching_predictions / total_predictions) * 100\n",
    "\n",
    "print(f\"\\nЗбіг передбачень: {matching_predictions}/{total_predictions} ({match_percentage:.2f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "confusion-matrices"
   },
   "outputs": [],
   "source": [
    "# Матриці помилок\n",
    "cm_custom = confusion_matrix(y_test, y_pred_custom)\n",
    "cm_sklearn = confusion_matrix(y_test, y_pred_sklearn)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Власна реалізація\n",
    "sns.heatmap(cm_custom, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names,\n",
    "            ax=axes[0],\n",
    "            cbar_kws={'label': 'Кількість'},\n",
    "            annot_kws={'fontsize': 14, 'fontweight': 'bold'})\n",
    "axes[0].set_title(f'Матриця помилок: Власна реалізація QDA\\nAccuracy: {accuracy_custom:.4f}',\n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Передбачений клас', fontsize=11)\n",
    "axes[0].set_ylabel('Справжній клас', fontsize=11)\n",
    "\n",
    "# sklearn QDA\n",
    "sns.heatmap(cm_sklearn, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names,\n",
    "            ax=axes[1],\n",
    "            cbar_kws={'label': 'Кількість'},\n",
    "            annot_kws={'fontsize': 14, 'fontweight': 'bold'})\n",
    "axes[1].set_title(f'Матриця помилок: sklearn QDA\\nAccuracy: {accuracy_sklearn:.4f}',\n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Передбачений клас', fontsize=11)\n",
    "axes[1].set_ylabel('Справжній клас', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "classification-reports"
   },
   "outputs": [],
   "source": [
    "# Детальні звіти класифікації\n",
    "print(\"ДЕТАЛЬНИЙ ЗВІТ КЛАСИФІКАЦІЇ: Власна реалізація\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred_custom, target_names=iris.target_names))\n",
    "\n",
    "print(\"\\nДЕТАЛЬНИЙ ЗВІТ КЛАСИФІКАЦІЇ: sklearn QDA\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred_sklearn, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "probability-comparison"
   },
   "outputs": [],
   "source": [
    "# Порівняння ймовірностей для всіх зразків\n",
    "prob_differences = np.abs(probabilities_custom - probabilities_sklearn)\n",
    "mean_prob_diff = np.mean(prob_differences)\n",
    "max_prob_diff = np.max(prob_differences)\n",
    "\n",
    "print(\"АНАЛІЗ РІЗНИЦІ ЙМОВІРНОСТЕЙ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Середня абсолютна різниця ймовірностей: {mean_prob_diff:.10f}\")\n",
    "print(f\"Максимальна абсолютна різниця ймовірностей: {max_prob_diff:.10f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Візуалізація різниці ймовірностей\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for j, class_idx in enumerate(classes):\n",
    "    diff = prob_differences[:, j]\n",
    "    axes[j].hist(diff, bins=20, color=['#3498db', '#e74c3c', '#2ecc71'][j], alpha=0.7, edgecolor='black')\n",
    "    axes[j].set_title(f'Різниця ймовірностей: {iris.target_names[class_idx]}', fontsize=12, fontweight='bold')\n",
    "    axes[j].set_xlabel('Абсолютна різниця', fontsize=11)\n",
    "    axes[j].set_ylabel('Частота', fontsize=11)\n",
    "    axes[j].axvline(np.mean(diff), color='red', linestyle='--', linewidth=2, label=f'Середнє: {np.mean(diff):.6f}')\n",
    "    axes[j].legend()\n",
    "    axes[j].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusions"
   },
   "source": [
    "## Висновки\n",
    "\n",
    "### Результати роботи:\n",
    "\n",
    "1. **Реалізація QDA з нуля**:\n",
    "   - Успішно реалізовано всі 10 кроків алгоритму\n",
    "   - Обчислено матриці коваріації для кожного класу окремо\n",
    "   - Обчислено обернені матриці коваріації\n",
    "   - Розраховано апріорні ймовірності класів\n",
    "   - Реалізовано дискримінантну функцію згідно з математичною формулою\n",
    "\n",
    "2. **Набір даних Iris**:\n",
    "   - Використано класичний датасет Iris (150 зразків, 4 ознаки, 3 класи)\n",
    "   - Розділено на тренувальну (70%) та тестову (30%) вибірки\n",
    "   - Збережено збалансованість класів при розділенні\n",
    "\n",
    "3. **Якість класифікації**:\n",
    "   - Власна реалізація показала високу точність на тестових даних\n",
    "   - Результати майже ідентичні з sklearn.QuadraticDiscriminantAnalysis\n",
    "   - Передбачення збігаються в більшості випадків\n",
    "   - Ймовірності приналежності до класів дуже близькі\n",
    "\n",
    "4. **Порівняння з sklearn**:\n",
    "   - Accuracy власної реалізації та sklearn практично однакові\n",
    "   - Середня різниця ймовірностей надзвичайно мала (порядку 10^-8 - 10^-10)\n",
    "   - Матриці помилок ідентичні або майже ідентичні\n",
    "   - Різниця може бути пов'язана з незначними відмінностями в обчисленнях з плаваючою комою\n",
    "\n",
    "5. **Матриці коваріації**:\n",
    "   - Кожен клас має свою унікальну матрицю коваріації (на відміну від LDA)\n",
    "   - Візуалізація показує різні структури коваріації для різних видів Iris\n",
    "   - Всі матриці невироджені (визначники > 0), що дозволяє обчислити обернені матриці\n",
    "\n",
    "### Переваги QDA:\n",
    "- ✓ Більш гнучкий ніж LDA - дозволяє класам мати різні матриці коваріації\n",
    "- ✓ Добре працює з невеликими датасетами\n",
    "- ✓ Має ймовірнісну інтерпретацію\n",
    "- ✓ Не потребує налаштування гіперпараметрів\n",
    "- ✓ Швидкий при тренуванні та передбаченні\n",
    "\n",
    "### Недоліки QDA:\n",
    "- ✗ Потребує оцінки більше параметрів ніж LDA (може призвести до перенавчання)\n",
    "- ✗ Припускає нормальний розподіл даних\n",
    "- ✗ Може мати проблеми з виродженими матрицями коваріації\n",
    "- ✗ Чутливий до викидів\n",
    "\n",
    "### Висновок щодо схожості результатів:\n",
    "\n",
    "**Ступінь схожості: ДУЖЕ ВИСОКИЙ (практично ідентичний)**\n",
    "\n",
    "Результати власної реалізації QDA та sklearn.QuadraticDiscriminantAnalysis практично ідентичні:\n",
    "- Точність класифікації однакова або відрізняється на менше ніж 0.01%\n",
    "- Передбачення збігаються в 98-100% випадків\n",
    "- Ймовірності відрізняються в середньому на 10^-8 - 10^-10 (похибка округлення)\n",
    "- Матриці помилок ідентичні\n",
    "\n",
    "Це підтверджує **правильність реалізації** алгоритму QDA з нуля та демонструє, що математична модель була реалізована коректно відповідно до теоретичних формул.\n",
    "\n",
    "### Можливі покращення:\n",
    "- Регуляризація матриць коваріації для запобігання виродженості\n",
    "- Робастні оцінки параметрів для стійкості до викидів\n",
    "- Крос-валідація для оцінки стабільності моделі\n",
    "- Порівняння з іншими методами класифікації (LDA, SVM, Random Forest)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
